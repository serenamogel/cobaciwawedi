<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>CPU Benchmark Performance: AI and Inferencing -</title><meta name=robots content="index,follow,noarchive"><meta name=description content="As technology progresses at a breakneck pace, so too do the demands of modern applications and workloads. With artificial intelligence (AI) and machine learning (ML) becoming increasingly intertwined with our daily computational tasks, it's paramount that our reviews evolve in tandem. Recognizing this, we have AI and inferencing benchmarks in our CPU test suite for 2024.&nbsp;
Traditionally, CPU benchmarks have focused on various tasks, from arithmetic calculations to multimedia processing. However, with AI algorithms now driving features within some applications, from voice recognition to real-time data analysis, it's crucial to understand how modern processors handle these specific workloads."><meta name=author content="Jenniffer Sheldon"><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/app.css><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/an-old-hope.min.css><script defer src=https://assets.cdnweb.info/hugo/paper/js/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=./theme.png><link rel=icon href=./favicon.ico><link rel=apple-touch-icon href=./apple-touch-icon.png><meta name=generator content="Hugo 0.98.0"><meta property="og:title" content="CPU Benchmark Performance: AI and Inferencing"><meta property="og:description" content="As technology progresses at a breakneck pace, so too do the demands of modern applications and workloads. With artificial intelligence (AI) and machine learning (ML) becoming increasingly intertwined with our daily computational tasks, it's paramount that our reviews evolve in tandem. Recognizing this, we have AI and inferencing benchmarks in our CPU test suite for"><meta property="og:type" content="article"><meta property="og:url" content="/intel-core-i9-14900ks-review-the-swan-song-of-raptor-lake-with-a-super-fast-6-2-ghz-turbo.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-04-25T00:00:00+00:00"><meta property="article:modified_time" content="2024-04-25T00:00:00+00:00"><meta itemprop=name content="CPU Benchmark Performance: AI and Inferencing"><meta itemprop=description content="As technology progresses at a breakneck pace, so too do the demands of modern applications and workloads. With artificial intelligence (AI) and machine learning (ML) becoming increasingly intertwined with our daily computational tasks, it's paramount that our reviews evolve in tandem. Recognizing this, we have AI and inferencing benchmarks in our CPU test suite for"><meta itemprop=datePublished content="2024-04-25T00:00:00+00:00"><meta itemprop=dateModified content="2024-04-25T00:00:00+00:00"><meta itemprop=wordCount content="284"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="CPU Benchmark Performance: AI and Inferencing"><meta name=twitter:description content="As technology progresses at a breakneck pace, so too do the demands of modern applications and workloads. With artificial intelligence (AI) and machine learning (ML) becoming increasingly intertwined with our daily computational tasks, it's paramount that our reviews evolve in tandem. Recognizing this, we have AI and inferencing benchmarks in our CPU test suite for"></head><body class=not-ready data-menu=true><header class=header><p class=logo><a class=site-name href=./index.html>DazeVlog</a><a class=btn-dark></a></p><script>let bodyClx=document.body.classList,btnDark=document.querySelector(".btn-dark"),sysDark=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark"),setDark=e=>{bodyClx[e?"add":"remove"]("dark"),localStorage.setItem("dark",e?"yes":"no")};setDark(darkVal?darkVal==="yes":sysDark.matches),requestAnimationFrame(()=>bodyClx.remove("not-ready")),btnDark.addEventListener("click",()=>setDark(!bodyClx.contains("dark"))),sysDark.addEventListener("change",e=>setDark(e.matches))</script><nav class=menu><a href=./sitemap.xml>Sitemap</a></nav></header><main class=main><article class=post-single><header class=post-title><p><time>Apr 25, 2024</time>
<span>Jenniffer Sheldon</span></p><h1>CPU Benchmark Performance: AI and Inferencing</h1></header><section class=post-content><p>As technology progresses at a breakneck pace, so too do the demands of modern applications and workloads. With artificial intelligence (AI) and machine learning (ML) becoming increasingly intertwined with our daily computational tasks, it's paramount that our reviews evolve in tandem. Recognizing this, we have AI and inferencing benchmarks in our CPU test suite for 2024.&nbsp;</p><p>Traditionally, CPU benchmarks have focused on various tasks, from arithmetic calculations to multimedia processing. However, with AI algorithms now driving features within some applications, from voice recognition to real-time data analysis, it's crucial to understand how modern processors handle these specific workloads. This is where our newly incorporated benchmarks come into play.</p><p>As chip makers such as AMD with Ryzen AI and Intel with their Meteor Lake mobile platform feature AI-driven hardware within the silicon, it seems in 2024, and we're going to see many applications using AI-based technologies coming to market.</p><p>We are using DDR5 memory on the Core i9-14900KS, as well as the other Intel 14th&nbsp;Gen Core series processors including the Core i9-14900K, the&nbsp;Core i7-14700K, Core i5-14600K, and Intel's 13th Gen at the relative JEDEC settings. The same methodology is also used for the AMD Ryzen 7000 series and Intel's 12th Gen (Alder Lake) processors. Below are the settings we have used for each platform:</p><ul><li>DDR5-5600B CL46 - Intel 14th & 13th Gen</li><li>DDR5-5200 CL44 - Ryzen 7000</li><li>DDR5-4800 (B) CL40 - Intel 12th Gen</li></ul><p><img alt="(6-1) ONNX Runtime 1.14: CaffeNet 12-int8 (CPU Only)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135496.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-1b) ONNX Runtime 1.14: CaffeNet 12-int8 (CPU Only)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135497.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-1c) ONNX Runtime 1.14: Super-Res-10 (CPU Only)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135498.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-1d) ONNX Runtime 1.14: Super-Res-10 (CPU Only)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135499.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-2) DeepSpeech 0.6: Acceleration CPU" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135500.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-3) TensorFlow 2.12: VGG-16, Batch Size 16 (CPU)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135501.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-3b) TensorFlow 2.12: VGG-16, Batch Size 64 (CPU)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135502.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-3d) TensorFlow 2.12: GoogLeNet, Batch Size 16 (CPU)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135503.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-3e) TensorFlow 2.12: GoogLeNet, Batch Size 64 (CPU)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135504.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-3f) TensorFlow 2.12: GoogLeNet, Batch Size 256 (CPU)" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135505.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-4) UL Procyon Windows AI Inference: MobileNet V3 (float32) " src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135506.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-4b) UL Procyon Windows AI Inference: ResNet 50 (float32) " src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135507.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="(6-4c) UL Procyon Windows AI Inference: Inception V4 (float32) " src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21378/135508.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>Regarding AI and inferencing workloads, there is virtually no difference or benefit from going for the Core i9-14900KS over the Core i9-14900K. While Intel takes the win in our TensorFlow-based benchmark, the AMD Ryzen 9 7950X3D, and 7950X both seem to better grasp the type of AI workloads we've tested.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH9yf5ZxZqKmpJq5bq%2FOq5xmoWlifnWFj2mirGWimsOqsdZmq6GdXajEorqMrKann12ks26%2BwKmrqKpdoa6ssYywoK2gXZZ6tMHPnqlmnpGowW6CjGtkoKCqYsG2vsGoZnA%3D</p></section><nav class=post-nav><a class=prev href=./sceptre-x270w-1080p-review-value-27-that-delivers.html><span>←</span><span>A Value 27&amp;quot; That Delivers</span></a>
<a class=next href=./josephine-hull-net-worth-62909.html><span>Josephine Hull Net Worth</span><span>→</span></a></nav></article></main><footer class=footer><p>&copy; 2024 <a href=./></a></p><p>Powered by <a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>️</p></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>